{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Логистическая регрессия. Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации называется бинарной кросс-энтропией и записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i))),$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация логистической регрессии будет основана на оптимизации функции ошибки градиентным спуском."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве экспериментальных данных возьмем датасет о доходах граждан в различных странах [Adult Income](https://archive.ics.uci.edu/ml/datasets/Adult) и сделаем необходимую предобработку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./data/adult.data',\n",
    "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                           'education-num', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'capital-gain',\n",
    "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание датасета\n",
    "\n",
    "# with open('./data/adult.names', 'r') as f:\n",
    "#     names = f.read()\n",
    "# print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "\n",
       "        marital-status        occupation    relationship    race    sex  \\\n",
       "0        Never-married      Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse   Exec-managerial         Husband   White   Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   salary  workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  ...  \\\n",
       "0       0             0                       0                     0  ...   \n",
       "1       0             0                       0                     0  ...   \n",
       "2       0             0                       0                     0  ...   \n",
       "3       0             0                       0                     0  ...   \n",
       "4       0             0                       0                     0  ...   \n",
       "\n",
       "   relationship_ Own-child  relationship_ Unmarried  relationship_ Wife  \\\n",
       "0                        0                        0                   0   \n",
       "1                        0                        0                   0   \n",
       "2                        0                        0                   0   \n",
       "3                        0                        0                   0   \n",
       "4                        0                        0                   1   \n",
       "\n",
       "   race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  race_ Black  \\\n",
       "0                         0                         0            0   \n",
       "1                         0                         0            0   \n",
       "2                         0                         0            0   \n",
       "3                         0                         0            1   \n",
       "4                         0                         0            1   \n",
       "\n",
       "   race_ Other  race_ White  sex_ Female  sex_ Male  \n",
       "0            0            1            0          1  \n",
       "1            0            1            0          1  \n",
       "2            0            1            0          1  \n",
       "3            0            0            0          1  \n",
       "4            0            0            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030671</td>\n",
       "      <td>-1.063611</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>0.148453</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837109</td>\n",
       "      <td>-1.008707</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-2.222153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042642</td>\n",
       "      <td>0.245079</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.057047</td>\n",
       "      <td>0.425801</td>\n",
       "      <td>-1.197459</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775768</td>\n",
       "      <td>1.408176</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "0  0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
       "1  0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
       "2 -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
       "3  1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
       "4 -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
       "\n",
       "   hours-per-week  salary  workclass_ ?  workclass_ Federal-gov  \\\n",
       "0       -0.035429       0             0                       0   \n",
       "1       -2.222153       0             0                       0   \n",
       "2       -0.035429       0             0                       0   \n",
       "3       -0.035429       0             0                       0   \n",
       "4       -0.035429       0             0                       0   \n",
       "\n",
       "   workclass_ Local-gov  ...  relationship_ Own-child  \\\n",
       "0                     0  ...                        0   \n",
       "1                     0  ...                        0   \n",
       "2                     0  ...                        0   \n",
       "3                     0  ...                        0   \n",
       "4                     0  ...                        0   \n",
       "\n",
       "   relationship_ Unmarried  relationship_ Wife  race_ Amer-Indian-Eskimo  \\\n",
       "0                        0                   0                         0   \n",
       "1                        0                   0                         0   \n",
       "2                        0                   0                         0   \n",
       "3                        0                   0                         0   \n",
       "4                        0                   1                         0   \n",
       "\n",
       "   race_ Asian-Pac-Islander  race_ Black  race_ Other  race_ White  \\\n",
       "0                         0            0            0            1   \n",
       "1                         0            0            0            1   \n",
       "2                         0            0            0            1   \n",
       "3                         0            1            0            0   \n",
       "4                         0            1            0            0   \n",
       "\n",
       "   sex_ Female  sex_ Male  \n",
       "0            0          1  \n",
       "1            0          1  \n",
       "2            0          1  \n",
       "3            0          1  \n",
       "4            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию sigmoid\n",
    "def sigmoid(X, theta):\n",
    "    return 1. / (1. + np.exp(-X.dot(theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, вычисляющую градиент бинарной кросс-энтропии\n",
    "def calc_binary_cross_entropy_grad(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(sigmoid(X, theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.18220152e+00, -3.15524980e-01,  8.98087390e-01,  7.61509306e-01,\n",
       "        6.37883564e-01, -6.37888463e-01,  6.21876481e-01, -7.81877921e-02,\n",
       "        4.24799786e-01,  3.36378365e-01,  3.38009780e-01,  8.58881427e-01,\n",
       "        9.74747564e-01,  9.33962074e-01, -7.85036544e-01,  6.93612812e-03,\n",
       "        4.08394474e-01,  4.91984312e-01,  5.62066615e-01,  1.42333149e+00,\n",
       "        9.78308166e-01,  1.14915955e+00,  6.90788800e-01,  4.35222964e-01,\n",
       "        6.46143233e-01,  5.34420479e-01,  6.18223280e-01,  1.61096748e+00,\n",
       "        9.09710550e-01, -4.28230037e-01,  8.40399041e-01,  8.85025416e-01,\n",
       "        3.24397258e-01,  1.05574662e+00,  3.62299888e-01,  5.89057982e-01,\n",
       "        9.88443132e-04, -2.97874470e-01,  6.11752440e-01,  8.11280626e-01,\n",
       "        7.95663040e-01, -1.59850366e-02,  9.64814314e-01,  3.30697269e-01,\n",
       "        5.20449527e-01,  2.58558666e-01,  2.21719660e+00,  1.59897859e-01,\n",
       "        9.48510850e-01,  2.28275110e-02,  1.02420428e+00, -1.39716497e+00,\n",
       "        8.35398252e-01, -1.29220590e-02,  7.79500017e-02,  1.02543563e+00,\n",
       "        2.36520366e-01,  7.68917996e-01,  6.08930383e-01,  6.22907129e-01,\n",
       "        9.87311090e-01,  3.38583874e-01,  1.08787945e+00,  9.95948149e-01,\n",
       "        5.53494533e-01,  2.32468515e-01,  3.95775461e-01])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logisitc_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Сделать предсказания на тренировочной выборке и\n",
    "# посчитать значение метрики accuracy и F1-score\n",
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)\n",
    "y_pred = sigmoid(X_valid, theta) > 0.5\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисовать ROC кривую\n",
    "def calc_and_plot_roc(y_true, y_pred_proba):\n",
    "    # Посчитать значения ROC кривой и значение площади под кривой AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.title('Receiver Operating Characteristic', fontsize=15)\n",
    "    plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "    plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Вычислить вероятности принадлежности классу 1 для каждого объекта из валидационной выборки\n",
    "y_pred_proba = sigmoid(X_valid, theta)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Добавление регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Оборачивание линейной регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegOptimizer():\n",
    "    def __init__(self, alpha, n_iters):\n",
    "        self.theta = None\n",
    "        self._alpha = alpha\n",
    "        self._n_iters = n_iters\n",
    "    \n",
    "    def gradient_step(self, theta, theta_grad):\n",
    "        return theta - self._alpha * theta_grad\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def optimize(self, X, y, start_theta, n_iters):\n",
    "        theta = start_theta.copy()\n",
    "\n",
    "        for _ in range(n_iters):\n",
    "            theta_grad = self.grad_func(X, y, theta)\n",
    "            theta = self.gradient_step(theta, theta_grad)\n",
    "\n",
    "        return theta\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m = X.shape[1]\n",
    "        start_theta = np.ones(m)\n",
    "        self.theta = self.optimize(X, y, start_theta, self._n_iters)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg(RegOptimizer):\n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = X.dot(self.theta)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "def prepare_boston_data():\n",
    "    data = load_boston()\n",
    "    X, y = data['data'], data['target']\n",
    "    # Нормализовать даннные с помощью стандартной нормализации\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinReg(0.01, 500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Оборачивание логистической регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(RegOptimizer):\n",
    "    def sigmoid(self, X, theta):\n",
    "        return 1. / (1. + np.exp(-X.dot(theta)))\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.sigmoid(X, self.theta)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = self.predict_proba(X) > 0.5\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_adult_data():\n",
    "    adult = pd.read_csv('./data/adult.data',\n",
    "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                               'education-num', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'capital-gain',\n",
    "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "    \n",
    "    # Избавиться от лишних признаков\n",
    "    adult.drop(['native-country'], axis=1, inplace=True)\n",
    "    # Сконвертировать целевой столбец в бинарные значения\n",
    "    adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "    # Сделать one-hot encoding для некоторых признаков\n",
    "    adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])\n",
    "    \n",
    "    # Нормализовать нуждающиеся в этом признаки\n",
    "    a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "    norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "    adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "    \n",
    "    # Разбить таблицу данных на матрицы X и y\n",
    "    X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "    y = adult['salary'].values\n",
    "\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogReg(1., 300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случаях линейной и логистической регрессии будем добавлять к функции ошибки регуляризующую часть как:\n",
    "$$\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $\\theta$ — вектор параметров линейной модели без фиктивного признака (intercept/bias term), $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Добавление регуляризатора в линейную регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После добавления регуляризации функция ошибки линейной регрессии будет выглядеть следующим образом:\n",
    "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} + \\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2}$$\n",
    "А ее градиент по параметру $\\theta$:\n",
    "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j} = \\frac{1}{n}X^T(X\\theta - y) + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegRegularized(LinReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LinRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinRegRegularized(alpha=0.01, lambd=0.05, n_iters=500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Добавление регуляризатора в логистическую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации с регуляризатором записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i)))+\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}+\\frac{\\lambda}{m}\\sum_{j}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegRegularized(LogReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LogRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogRegRegularized(alpha=1., lambd=1., n_iters=300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
